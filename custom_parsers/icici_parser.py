# Auto-generated by agent.py
import pandas as pd
import pdfplumber
import re
from collections import defaultdict

def parse(pdf_path: str) -> pd.DataFrame:
    all_data = []
    
    with pdfplumber.open(pdf_path) as pdf:
        for page_num, page in enumerate(pdf.pages):
            words = page.extract_words()

            header_bottom = 0
            header_x_coords = {}
            found_header = False
            
            # 1) Find the header line containing 'Date', 'Description', 'Balance', 'Debit', 'Credit'
            # Group words by rounded top coordinate to form lines
            words_by_line = defaultdict(list)
            for word in words:
                line_key = round(word['top'], 2) 
                words_by_line[line_key].append(word)

            sorted_line_keys = sorted(words_by_line.keys())

            for line_key in sorted_line_keys:
                line_words = sorted(words_by_line[line_key], key=lambda x: x['x0'])
                line_text = " ".join([w['text'] for w in line_words])

                # Check if the line contains all required header components
                if all(keyword in line_text for keyword in ['Date', 'Description', 'Balance', 'Debit', 'Credit']):
                    
                    # Record x0 positions for each relevant header word
                    for word_obj in line_words:
                        if word_obj['text'] == 'Date':
                            header_x_coords['Date'] = word_obj['x0']
                        elif word_obj['text'] == 'Description':
                            header_x_coords['Description'] = word_obj['x0']
                        elif word_obj['text'] == 'Debit': # Use 'Debit' word's x0 for 'Debit Amt' column
                            header_x_coords['Debit Amt'] = word_obj['x0']
                        elif word_obj['text'] == 'Credit': # Use 'Credit' word's x0 for 'Credit Amt' column
                            header_x_coords['Credit Amt'] = word_obj['x0']
                        elif word_obj['text'] == 'Balance':
                            header_x_coords['Balance'] = word_obj['x0']

                    # Verify all target header x0s were found
                    if all(col in header_x_coords for col in ['Date', 'Description', 'Debit Amt', 'Credit Amt', 'Balance']):
                        # FIX: Add a small buffer to header_bottom to ensure the header line itself
                        # is not picked up by the subsequent crop and extract_words.
                        header_bottom = max(w['bottom'] for w in line_words) + 1 
                        found_header = True
                        break
            
            if not found_header:
                # If header is not found on this page, and it's not the first page, skip it.
                # If it's the first page and no header, raise an error.
                if page_num == 0:
                    raise ValueError("Header line not found in the PDF on the first page.")
                continue # Skip to the next page if no header (e.g., summary pages or blank pages)

            # 2) Record x0 positions for each header (left boundaries), append page.width as rightmost boundary.
            column_names = ['Date', 'Description', 'Debit Amt', 'Credit Amt', 'Balance']
            
            # Prepare x-coordinates of the header words in the logical order of columns
            header_word_x_coords_ordered = [
                header_x_coords['Date'],
                header_x_coords['Description'],
                header_x_coords['Debit Amt'], 
                header_x_coords['Credit Amt'],
                header_x_coords['Balance']
            ]
            
            # Define column boundaries based on midpoints of header x-coordinates
            ordered_boundaries = []
            current_left_x_boundary = page.bbox[0] # Start first column from the absolute left of the page
            
            for i, col_name in enumerate(column_names):
                if i < len(header_word_x_coords_ordered) - 1:
                    # The right boundary of current column is the midpoint between its header and the next header
                    midpoint_x = (header_word_x_coords_ordered[i] + header_word_x_coords_ordered[i+1]) / 2
                    right_x_boundary = midpoint_x
                else:
                    # The last column extends to the right edge of the page
                    right_x_boundary = page.width
                
                ordered_boundaries.append((col_name, current_left_x_boundary, right_x_boundary))
                current_left_x_boundary = right_x_boundary # Next column starts where this one ends

            # 3) Crop below header and extract_words() from the cropped page.
            # The header_bottom was adjusted by +1 to ensure header itself is not included.
            cropped_page = page.crop((0, header_bottom, page.width, page.height))
            data_words = cropped_page.extract_words()

            # 4) Group words into rows by rounded 'top'.
            data_words_by_line = defaultdict(list)
            for word in data_words:
                line_key = round(word['top'], 2)
                data_words_by_line[line_key].append(word)

            # 5) For each row, place each word into the correct column by checking x0 against header boundaries.
            # 6) Join adjacent words in same column with single spaces.
            current_page_data = []
            for line_key in sorted(data_words_by_line.keys()):
                line_words = sorted(data_words_by_line[line_key], key=lambda x: x['x0'])
                row_data_dict = {col_name: [] for col_name in column_names}

                for word in line_words:
                    for col_name, left_bound, right_bound in ordered_boundaries:
                        # Assign word to the column whose x-range its x0 falls into
                        if left_bound <= word['x0'] < right_bound:
                            row_data_dict[col_name].append(word['text'])
                            break # Move to the next word once assigned

                # Join collected words for each column
                parsed_row = [
                    " ".join(row_data_dict['Date']).strip(),
                    " ".join(row_data_dict['Description']).strip(),
                    " ".join(row_data_dict['Debit Amt']).strip(),
                    " ".join(row_data_dict['Credit Amt']).strip(),
                    " ".join(row_data_dict['Balance']).strip()
                ]
                
                # Filter out empty rows or non-data rows (e.g., footers, page numbers)
                # A valid data row should at least have a Date.
                if parsed_row[0]: 
                    all_data.append(parsed_row)
    
    # 7) Return a pandas.DataFrame with exact column names and types matching the CSV
    df = pd.DataFrame(all_data, columns=column_names)

    # Convert numeric columns to float, treating empty strings as NaN for pd.DataFrame.equals comparison
    for col in ['Debit Amt', 'Credit Amt', 'Balance']:
        # Replace empty strings with NaN for numeric conversion
        df[col] = df[col].replace('', float('nan'))
        df[col] = pd.to_numeric(df[col], errors='coerce')

    return df
